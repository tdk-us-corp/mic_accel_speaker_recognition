# ################################
# Model: Speaker Verification Baseline
# Authors: Hwidong Na 2020
#          Mirco Ravanelli 2020
# ################################

seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Folders and train_log file
data_folder: test
output_folder: /mnt/009-Audio/Internships/AccelAuthentification/training_data/results/inference_test/<seed>
save_folder: !ref <output_folder>/save/



verification_file: verification_pairs.txt

# Here, the pretrained embedding model trained with train_speaker_embeddings.py hparams/train_ecapa_tdnn.yaml
# is downloaded from the speechbrain HuggingFace repository.
# However, a local path pointing to a directory containing your checkpoints may also be specified
# instead (see pretrainer below)
pretrain_path: ep19_best

# csv files
# train_data: !ref <save_folder>/train.csv
# enrol_data: !ref <save_folder>/enrol.csv
# test_data: !ref <save_folder>/test.csv
# split_ratio: [90, 10]
# skip_prep: False

batch_size: 8
# score_norm: s-norm  # z-norm t-norm s-norm (uncomment to enable it)
# cohort_size: 20000 # amount of imposter utterances in normalization cohort
# n_train_snts: 400000 # used for normalization stats

# Feature parameters
# n_mels: 80
n_MFCC : 13
n_mel_channels: 80
hop_length: 256
win_length: 1024
n_fft: 1024
mel_fmin: 0.0
mel_fmax: 8000.0
mel_normalized: False
power: 1
norm: "slaney"
mel_scale: "slaney"
dynamic_range_compression: True
use_tacotron2_mel_spec: True



reduction_factor: 2
last_kernel_original : 3072
kernels_dim_original : 1024


# Dataloader options
train_dataloader_opts:
    batch_size: !ref <batch_size>

enrol_dataloader_opts:
    batch_size: !ref <batch_size>

test_dataloader_opts:
    batch_size: !ref <batch_size>

compute_features: !name:speechbrain.lobes.models.Tacotron2.mel_spectogram
    # sample_rate: 16000
    hop_length: !ref <hop_length>
    win_length: !ref <win_length>
    n_fft: !ref <n_fft>
    n_mels: !ref <n_mel_channels>
    f_min: !ref <mel_fmin>
    f_max: !ref <mel_fmax>
    power: !ref <power>
    normalized: !ref <mel_normalized>
    norm: !ref <norm>
    mel_scale: !ref <mel_scale>
    compression: !ref <dynamic_range_compression>

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: sentence
    std_norm: False

mean_var_norm_emb: !new:speechbrain.processing.features.InputNormalization
    norm_type: global
    std_norm: False
    
embedding_model: !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN
    input_size: !ref <n_MFCC>
    channels: [64, 64, 64, 64, 192]
    kernel_sizes: [5, 3, 3, 3, 1]
    dilations: [1, 2, 3, 4, 1]
    groups: [1, 1, 1, 1, 1]
    attention_channels: 64
    lin_neurons: 192

pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
    collect_in: !ref <save_folder>
    loadables:
        embedding_model: !ref <embedding_model>
    paths:
        embedding_model: !ref <pretrain_path>/embedding_model.ckpt
